\documentclass[compsoc]{IEEEtran}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{authblk}
\usepackage[english]{babel}
\usepackage{blindtext}
%\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
%\usepackage{algorithmic,float}
\usepackage{setspace}
\usepackage{amsfonts}
%\usepackage{hyperref}
\graphicspath{ {../images/} }
\usepackage{subfig}
\usepackage{fontspec}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage[bottom]{footmisc}
\newfontfamily\listingsfont[Scale=.7]{inconsolata}\usepackage[font=footnotesize,labelfont=bf]{caption}
\newcommand\todo[1]{\textcolor{red}{\textbf{TODO: #1}}}
%\captionsetup[algorithm2e]{font=footnotesize}
\usepackage[table,xcdraw]{xcolor}
\usepackage[utf8]{inputenc}
\title{Assignment: Transfer Learning on Intel Image Classification}
\author{David Bertoldi -- 735213 \\ email: d.bertoldi@campus.unimib.it}
\affil{Department of Informatics, Systems and Communication}
\affil{University of Milano-Bicocca}
\date{October 2022}


\begin{document}

\maketitle 



\section{Dataset}\label{sec:insp}
The chosen dataset is called Intel$^\circledR$ Image Classification and it was initially published on Analytics Vidhya by Intel$^\circledR$ to host an image classification challenge to promote OpenVINOâ„¢, a toolkit or optimizing and deploying AI inference \cite{site1}\cite{site2}. \par

The dataset contains images of natural scenes around the world and they belong to $6$ classes: buildings, forests, glaciers, mountains, sea and streets. The images are of size $150\times150$px and can be colored ($3$ channels, RGB) or rarely in grayscale (still with $3$ channels). Figure \ref{fig:samples} shows $16$ entries of the training dataset. \par
There is a total of ${\sim 24\,000}$ images, divided into Train (${\sim14\,000}$), Test (${\sim3\,000}$) and Prediction (${\sim7\,000}$) folders. The last one does not contain labels and it is intended for unsupervised learning and it will be ignored in this work.



\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=2.5in]{../images/samples.png}
\captionsetup{justification=centering}                                                                                         
\caption{$16$ random entries of the train dataset}
\label{fig:samples}                                                                                                                               
\end{figure}

The distribution of the images across the classes follows a uniform distribution $U(\mu, \sigma)$: in the train set each class has an average $\mu = 2\,339$ images with $\sigma = 105.45$ and in the test set $\mu=500$ and $\sigma=36.92$. We didn't find any bias inside the dataset since all the classes are equally populated and so we didn't applied any kind of data augmentation on particular classes for rebalacing.


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/data.png}
\captionsetup{justification=centering}                                                                                         
\caption{16 entries of the train dataset}
\label{fig:data}                                                                                                                               
\end{figure}

The $6$ classes are encoded with numbers $0$ to $5$ and Table \ref{tab:encode} shows the mapping between the numerical and nominative form.



\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\rowcolor[HTML]{9698ED} 
{\color[HTML]{FFFFFF} \textbf{Number}} & {\color[HTML]{FFFFFF} \textbf{Class}} \\ \hline
0                                      & Mountain                              \\ \hline
1                                      & Street                                \\ \hline
2                                      & Glacier                               \\ \hline
3                                      & Building                              \\ \hline
4                                      & Sea                                   \\ \hline
5                                      & Forest                                \\ \hline
\end{tabular}
\caption{Mapping between numbers and names}
\label{tab:encode}
\end{table}



\section{The model} 
The chosen dataset presented similarieties with ImageNet: the $6$ classes of Intel$^\circledR$ Image Classification are scattered and distributed in the $1\,000$ classes of ImageNet. For this reason a pretrained model on ImageNet speeded up the learning process. The chosen model is VGG16, a $16-$layers deep CNN proposed by Karen Simonyan and Andrew Zisserman at the University of Oxford\cite{vgg16}. Figure \ref{fig:vgg16} shows an overview of its architecture.

\todo{preprocessing}


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/vgg16.png}
\captionsetup{justification=centering}                                                                                         
\caption{Architecture of VGG16 with the cuts applied in this work}
\label{fig:vgg16}                                                                                                                               
\end{figure}

In this work we proposed different cuts to the network and feeded its outputs to a "classic" machine learning model, a SVM, and benchmark the performance of the hybrid architecture. \par

The chosen cuts were after the first dense layer (\texttt{fc1}), after the fourth pooling layer (\texttt{block4\_pool}) 
and after the third pooling layer (\texttt{block3\_pool}). The different cuts led to different challenges, such as the high dimensionality of the features.


As the cuts approached the input, the number of trainable parameters decreased exponentially; however the representation of the features will have an increasingly higher dimension. The higher dimensionality affects the training performance of the SVM and a fine tuning on the management of the memory. For this reason we used less samples during the training phase as the dimensionality increased, raising the risk of underfitting. Table \ref{tab:dims} describes the numbers of the problems.


\begin{table}[]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|c|l|}
\hline
\rowcolor[HTML]{9698ED} 
{\color[HTML]{FFFFFF} \textbf{Cut}} & {\color[HTML]{FFFFFF} \textbf{Trainable parameters}} & {\color[HTML]{FFFFFF} \textbf{Dimension}} \\ \hline
\texttt{fc1}                                 & $117\,479\,232$  & $1\times1\times4096=\mathbf{4\,096}$                             \\ \hline
\texttt{block4\_pool}                        & $7\,635\,264$  & $14\times14\times512 = \mathbf{100\,352}$                      \\ \hline
\texttt{block3\_pool}                        & $1\,735\,488$  & $28\times28\times256= \mathbf{200\,704}$                         \\ \hline
\end{tabular}}
\caption{Number of VGG16's trainable parameters and dimensions of the extracted features at each cutting point}
\label{tab:dims}
\end{table}




\section{First cutting point: \texttt{fc1}}\label{sec:fc1}

Before attaching to the layer \texttt{fc1} the SVM, it is interesting to visualize the features through PCA (Principal Component Analysis): we decreased the number of dimensions of the extracted features from $4\,096$ to $2$ and plotted the graph in Figure \ref{fig:pca1}.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/pca-1.png}
\captionsetup{justification=centering}                                                                                         
\caption{Architecture of VGG16 with the cuts applied in this work}
\label{fig:pca1}                                                                                                                               
\end{figure}

In the projection through PCA are identifiable some clusters: glaciers and mountains are very similar, the same goes for streets and buildings. This make sense since the picture of the mountains may contain snow or ice and picture of buildings may contain the surrounding street, and viceversa. The seas borders with the glaciers but it does not blend with them. The forests are a separate concepts and it seems to not share anything with the other classes. \par
Because the cut is very close to the VGG16's original output we expected an high accuracy in classifying the images.




\subsection{Extraction of the features and training of the SVM}
Before starting with the training of the hybrid model, we chose the SVM's hyperparameters using \texttt{GridSearchCV} from sklearn. This function does an exhaustive search of the best parameters for the SVM in order to find the best separation hyperplane. The parameters to be chosen were the cost $C \in \{5, 10, 20, 100\}$ and the kernel coefficient $\gamma \in \{scale, auto\}$. This does not assure that it gives back the best configurations on unseen data. As a matter of fact we should had the best results with cost $C=100$ and $\gamma=auto$ (Figure \ref{fig:costs}), but in this case we achieved higher performances on the test dataset with $C=100$ and $\gamma=scale$. So we used \texttt{GridSearchCV} just like a starting point for further manual experimentations.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/costs.png}
\captionsetup{justification=centering}                                                                                         
\caption{Model's performance on the training set with different configurations}
\label{fig:costs}                                                                                                                               
\end{figure}

An issue when using hybrid models are some incompatabilities between libraries: we started using Tensorflow's \texttt{DirectoryIterator} or \texttt{Dataset} in order to efficiently load the dataset in batches and to not saturate the memory; unfortunately sklearn does not support this kind of data structure and the only feasible solution was to diminuish the number of samples during the training and test phases. With this cutting point we used $800$ images per class when training and $300$ when testing. \par
The training accuracy reached $100\%$ and Figure \ref{fig:cm1-train} shows the confusion matrix. 


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm1-train.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on training dataset \\ (cut at \texttt{fc1} + SVM($C=100, \gamma=scale$))}
\label{fig:cm1-train}                                                                                                                               
\end{figure}

The test accuracy reached $92\%$ and Figure \ref{fig:cm1-test} shows the confusion matrix. We can notice a little confusion between mountains and glaciers and between streets and buildings. This results are in accordance with Figure \ref{fig:pca1}.


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm1-test.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on test dataset \\ (cut at \texttt{fc1} + SVM($C=100, \gamma=scale$)))}
\label{fig:cm1-test}                                                                                                                               
\end{figure}

The training phase for SVM took ${\sim550}$ seconds. We tried to simplify the model and thus decrease the timings by reducing the dimensionality of the features. In order to do so we used PCA as technique for dimensionality reduction.


\subsection{Dimensionality Reduction}
In this section we describe how we achieved high accuracy by reducing the dimensionality of the features in input.\par
Before applying PCA, we estimated how many components were needed to describe the data. This can be determined by looking at the \emph{cumulative explained variance} ratio as a function of the number of components.

The curve in Figure \ref{fig:var1} quantifies how much of the total $4096-$dimensional variance is contained within the first $n$ components. For example, we saw that the first ${\sim400}$ components contain approximately $80\%$ of the variance, while are needed around $2\,500$ components to describe $100\%$ of the variance.
\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/var-1.png}
\captionsetup{justification=centering}                                                                                         
\caption{The cumulative explained variance of the $4\,096$ components}
\label{fig:var1}                                                                                                                               
\end{figure}
We chose a configuration that could preserve $90\%$ of the variance, \emph{i.e.} $777$ components. This could assure good perfomances while using just $19\%$ of the dimensions.\par
In this case we found the optimal configuration of the SVM with $C=5$ and $\gamma=scale$.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm1-pca-train.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on training dataset \\ (cut at \texttt{fc1} + PCA + SVM($C=5, \gamma=scale$))}
\label{fig:cm1-pca-train}                                                                                                                               
\end{figure}


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm1-pca-test.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on test dataset \\ (cut at \texttt{fc1} + PCA + SVM($C=5, \gamma=scale$))}
\label{fig:cm1-pca-test}                                                                                                                               
\end{figure}
Figure \ref{fig:cm1-pca-train} and \ref{fig:cm1-pca-test} shows the confusion matrix after training and testing. We can see that there is a slight worsening in training accuracy ($99.9\%$) while test accuracy dropped to $88\%$. We noticed that the model still confused glaciers with mountain and streets with buildings; in addition to them, some of the images of the sea are mistaken for mountains and glaciers. That means the model is affected by more overfitting before applying PCA. \par
The lower accuracy and higher overfitting are traded off with faster times in training: we measured a speed up of almost $10$ times, reaching $57$ seconds.












\section{Second cutting point: \texttt{block4\_pool}}


Like in section \ref{sec:fc1} we repeated the experiment of visualizing the features extracted from layer \texttt{block4\_pool} through PCA and plotted the graph in Figure \ref{fig:pca2}.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/pca-2.png}
\captionsetup{justification=centering}                                                                                         
\caption{Architecture of VGG16 with the cuts applied in this work}
\label{fig:pca2}                                                                                                                               
\end{figure}

This time the sea, glacier and mountain classes collapsed in one cluster. This anticipated that images belonging to these classes could be classified with lower accuracy.
The cluster of images of forest is the only one that did not collide with any other.
We also noticed more isolated images being completely misclassified than the previous cut, \emph{e.g.} some images of mountain or sea are predicted as building or street.
\par



At this stage the number of trainable parameters of the CNN decreased by ${\sim93.5\%}$ but the dimensionality of the features increased 25 times, reaching $100\,352$. This made the application of PCA more crucial. 


\subsection{Extraction of the features and training of the SVM}
We performed an exhaustive search with \texttt{GridSearchCV} plus some manual experimentation and we found that a good configuration for the SVM is $C=10$ and $\gamma=scale$. Because of the increased dimensionality we used less images for training (from $800$ to $500$) in order to not saturate the memory. 	\par

The training accuracy reached again $100\%$ and Figure \ref{fig:cm2-train} shows the confusion matrix. 


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm2-train.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on training dataset \\ (cut at \texttt{block4\_pool} + SVM($C=10, \gamma=scale$))}
\label{fig:cm2-train}                                                                                                                               
\end{figure}

The test accuracy reached $89\%$ and Figure \ref{fig:cm2-test} shows the confusion matrix. We can notice the aforementioned confusion between sea and mountain or glaciers but is not compromising the overall accuracy of the model.


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm2-test.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on test dataset \\ (cut at \texttt{block4\_pool} + SVM($C=10, \gamma=scale$)))}
\label{fig:cm2-test}                                                                                                                               
\end{figure}

\subsection{Dimensionality Reduction}

We proceeded with the estimation of the optimal number of components in order to describe at least the $90\%$ of the variance.
From Figure \ref{fig:var2} we can notice that the $90\%$ of the variance can be described with $1\,850$ components, leading to a compression of $39\%$.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/var-2.png}
\captionsetup{justification=centering}                                                                                         
\caption{The cumulative explained variance of the $3\,000$ components}
\label{fig:var2}                                                                                                                               
\end{figure}


Please note that PCA operated on a dataset $D \in \mathcal{M}_{m \times n}$ calculates the maximum number of components to keep
$c = min\{m, n\}$. \par

In this case the optimal configuration for the SVM was $C=5$ and $\gamma=scale$; the model reached again $100\%$ of accuracy on the training data and $86\%$ on the test data. 

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm2-pca-train.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on training dataset \\ (cut at \texttt{block4\_pool} + PCA + SVM($C=5, \gamma=scale$))}
\label{fig:cm2-pca-train}                                                                                                                               
\end{figure}


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm2-pca-test.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on test dataset \\ (cut at \texttt{block4\_pool} + PCA + SVM($C=5, \gamma=scale$))}
\label{fig:cm2-pca-test}                                                                                                                               
\end{figure}

From Figure \ref{fig:cm2-pca-test} we noticed that images of streets or buildings were confused with forests for the first time; the more accurate classifications were regstered for images of street, glacier and sea. 
The application of a technique of dimensionality reduction
decreased the test accuracy of a reasonable amount, it didn't resolved the problem of overfitting (which is not guaranteed by PCA) but decreased the training times from $633$ seconds to $58$ seconds. 











\section{Second cutting point: \texttt{block3\_pool}}


Like in section \ref{sec:fc1} we repeated the experiment of visualizing the features extracted from layer \texttt{block3\_pool} through PCA and plotted the graph in Figure \ref{fig:pca3}.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/pca-3.png}
\captionsetup{justification=centering}                                                                                         
\caption{Architecture of VGG16 with the cuts applied in this work}
\label{fig:pca3}                                                                                                                               
\end{figure}

This time the sea, glacier and mountain classes collapsed in one cluster. This anticipated that images belonging to these classes could be classified with lower accuracy.
The cluster of images of forest is the only one that did not collide with any other.
We also noticed more isolated images being completely misclassified than the previous cut, \emph{e.g.} some images of mountain or sea are predicted as building or street.
\par



At this stage the number of trainable parameters of the CNN decreased by ${\sim93.5\%}$ but the dimensionality of the features increased 25 times, reaching $100\,352$. This made the application of PCA more crucial. 


\subsection{Extraction of the features and training of the SVM}
We performed an exhaustive search with \texttt{GridSearchCV} plus some manual experimentation and we found that a good configuration for the SVM is $C=10$ and $\gamma=scale$. Because of the increased dimensionality we used less images for training (from $800$ to $500$) in order to not saturate the memory. 	\par

The training accuracy reached again $100\%$ and Figure \ref{fig:cm3-train} shows the confusion matrix. 


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm3-train.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on training dataset \\ (cut at \texttt{block3\_pool} + SVM($C=10, \gamma=scale$))}
\label{fig:cm3-train}                                                                                                                               
\end{figure}

The test accuracy reached $89\%$ and Figure \ref{fig:cm3-test} shows the confusion matrix. We can notice the aforementioned confusion between sea and mountain or glaciers but is not compromising the overall accuracy of the model.


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm3-test.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on test dataset \\ (cut at \texttt{block3\_pool} + SVM($C=10, \gamma=scale$)))}
\label{fig:cm3-test}                                                                                                                               
\end{figure}

\subsection{Dimensionality Reduction}

We proceeded with the estimation of the optimal number of components in order to describe at least the $90\%$ of the variance.
From Figure \ref{fig:var3} we can notice that the $90\%$ of the variance can be described with $1\,560$ components, leading to a compression of $35\%$.

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3.5in]{../images/var-3.png}
\captionsetup{justification=centering}                                                                                         
\caption{The cumulative explained variance of the $3\,000$ components}
\label{fig:var3}                                                                                                                               
\end{figure}



In this case the optimal configuration for the SVM was $C=5$ and $\gamma=scale$; the model reached again $100\%$ of accuracy on the training data and $86\%$ on the test data. 

\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm3-pca-train.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on training dataset \\ (cut at \texttt{block3\_pool} + PCA + SVM($C=5, \gamma=scale$))}
\label{fig:cm3-pca-train}                                                                                                                               
\end{figure}


\begin{figure}[ht!]
\centering                                                                        
\includegraphics[width=3in]{../images/cm3-pca-test.png}
\captionsetup{justification=centering}                                                                                         
\caption{Confusion matrix on test dataset \\ (cut at \texttt{block3\_pool} + PCA + SVM($C=5, \gamma=scale$))}
\label{fig:cm3-pca-test}                                                                                                                               
\end{figure}

From Figure \ref{fig:cm3-pca-test} we noticed that images of streets or buildings were confused with forests for the first time; the more accurate classifications were regstered for images of street, glacier and sea. 
The application of a technique of dimensionality reduction
decreased the test accuracy of a reasonable amount, it didn't resolved the problem of overfitting (which is not guaranteed by PCA) but decreased the training times from $1340$ seconds to $160$ seconds.


\section{Conclusions}
In general, features extracted at deeper layers (closer to the original output) produced features that guaranteed highly accurate classifications, with $92\%$ 
of accuracy on test data. Appliying cuttings at higher level (closer to the input) the dimensionality of the features increased so much that the usage of techniques of  dimensional reduction became crucial in order to use them in the SVM classifier. Performances, in terms of accuracy and training time, got worse and  we note the presence of overfitting especially in the last classifiers. The results in this works are affected by the memory limitations; without these limitations the results could be different.



\bibliographystyle{ieeetr}
\bibliography{Bibliography}

\begin{thebibliography}{9}

\bibitem{site1} 
Practice Problem: Intel Scene Classification Challenge \\
\texttt{https://datahack.analyticsvidhya.com/contest/practice-problem-intel-scene-classification-challe}

\bibitem{site2} 
OpenVINOâ„¢ documentation \\
\texttt{https://docs.openvino.ai/latest/index.html}

\bibitem{vgg16}
\emph{Very Deep Convolutional Networks for Large-Scale Image Recognition} \\
Karen Simonyan, Andrew Zisserman \\
\texttt{https://doi.org/10.48550/arXiv.1409.1556}

\end{thebibliography}

\end{document}









