\relax 
\@nameuse{bbl@beforestart}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Dataset}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Inspecting the data}{1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sample of the first 16 unique samples\relax }}{1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sample}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Histogram of the frequency of samples in the dataset\relax }}{1}\protected@file@percent }
\newlabel{fig:datahist}{{2}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Difficult to read numbers\relax }}{1}\protected@file@percent }
\newlabel{fig:unread}{{3}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Preparing the data}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Unregularized FFNN}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The network}{2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Architecture of the unregularized network\relax }}{2}\protected@file@percent }
\newlabel{fig:noregffnn}{{4}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Training}{2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Loss (unregularized)\relax }}{2}\protected@file@percent }
\newlabel{fig:loss1}{{5}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Categorical accuracy (unregularized)\relax }}{2}\protected@file@percent }
\newlabel{fig:acc1}{{6}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Confusion matrix of the evaluation of the test set (unregularized network)\relax }}{3}\protected@file@percent }
\newlabel{fig:noregcm}{{7}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Evaluation}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Regularized FFNN}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The network}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Regularization techniques}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Data augmentation}{3}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Data augmentation algorithm\relax }}{3}\protected@file@percent }
\newlabel{alg:aug}{{1}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}L1 and L2}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Dropout}{3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Architecture of the network with dropout\relax }}{4}\protected@file@percent }
\newlabel{fig:regffnn}{{8}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Early stopping}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Loss (unregularized)\relax }}{4}\protected@file@percent }
\newlabel{fig:loss2}{{9}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Evaluation}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Categorical accuracy (unregularized)\relax }}{4}\protected@file@percent }
\newlabel{fig:acc2}{{10}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion matrix of the evaluation of the test set (regularized network)\relax }}{4}\protected@file@percent }
\newlabel{fig:regcm}{{11}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Autoencoding}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The nerwork}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces MSE vs. number of epochs vs. compression factor\relax }}{5}\protected@file@percent }
\newlabel{fig:multiacc}{{12}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces MSE with different compression factors\relax }}{5}\protected@file@percent }
\newlabel{fig:mse}{{13}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Training}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Final architecture of the autoencoder: in green the input, in yellow the encoders, in blue the latent layer, in red the encoder and in purple the output\relax }}{5}\protected@file@percent }
\newlabel{fig:auto}{{14}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Evaluation}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces First row: original test data. Second row: the same input but reproduced by the autoencoder.\relax }}{5}\protected@file@percent }
\newlabel{fig:reproduce}{{15}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Generation}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces \relax }}{6}\protected@file@percent }
\newlabel{fig:generator}{{16}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces New samples generated from a uniform distribution\relax }}{6}\protected@file@percent }
\newlabel{fig:unif}{{17}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces \relax }}{6}\protected@file@percent }
\newlabel{fig:enco}{{18}{6}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Simulator\relax }}{6}\protected@file@percent }
\newlabel{alg:ran}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces \relax }}{6}\protected@file@percent }
\newlabel{fig:gen}{{19}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Combination of the latent representation with SVMs}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Architecture}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Architecture of the encoder that feeds the SVM\relax }}{7}\protected@file@percent }
\newlabel{fig:svm}{{20}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Accuracy vs. cost parameter $C$ (logarithmic scale)\relax }}{7}\protected@file@percent }
\newlabel{fig:svmacc}{{21}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Confusion matrix of the hybrid model with $C=10$\relax }}{7}\protected@file@percent }
\newlabel{fig:c10}{{22}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{7}\protected@file@percent }
